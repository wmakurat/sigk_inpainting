{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpLRl1P_bzhv",
        "outputId": "dd65af7a-c898-440f-d0f5-606b74319de4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip\n",
            "To: /content/DIV2K_valid_HR.zip\n",
            "100% 449M/449M [00:21<00:00, 20.8MB/s]\n",
            "Downloading...\n",
            "From: http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
            "To: /content/DIV2K_train_HR.zip\n",
            "100% 3.53G/3.53G [02:34<00:00, 22.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip\n",
        "!gdown http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
        "!unzip -q DIV2K_valid_HR.zip\n",
        "!unzip -q DIV2K_train_HR.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu121"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRflaDoHdVQy",
        "outputId": "1996326e-bee1-4157-cc4e-75621e8b209d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.4.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.1%2Bcu121-cp312-cp312-linux_x86_64.whl (798.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.9/798.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.19.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.1%2Bcu121-cp312-cp312-linux_x86_64.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m135.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.4.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.1%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m116.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (2025.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.4.1) (75.2.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m121.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.0.0 (from torch==2.4.1)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.1) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.1) (11.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.4.1) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.4.1) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.23.0+cu126\n",
            "    Uninstalling torchvision-0.23.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.8.0+cu126\n",
            "    Uninstalling torchaudio-2.8.0+cu126:\n",
            "      Successfully uninstalled torchaudio-2.8.0+cu126\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.1+cu121 torchaudio-2.4.1+cu121 torchvision-0.19.1+cu121 triton-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "import random\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "import time\n",
        "import csv\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "1QfTX93bchPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lpips"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucaSta2S7HYu",
        "outputId": "ea778404-2fc0-4357-ba02-502a49a448ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lpips\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from lpips) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from lpips) (0.19.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.12/dist-packages (from lpips) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from lpips) (1.16.3)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.12/dist-packages (from lpips) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (2025.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (75.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->lpips) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=0.4.0->lpips) (12.6.85)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.2.1->lpips) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=0.4.0->lpips) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch>=0.4.0->lpips) (1.3.0)\n",
            "Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lpips\n",
            "Successfully installed lpips-0.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lpips"
      ],
      "metadata": {
        "id": "o399amUPcjEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EhWFY20q9Obb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade scikit-image\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5rF9F508qVK",
        "outputId": "1001929f-bbc3-4fef-881e-6dace26bb9e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (1.16.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2025.10.16)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "import cv2\n",
        "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
        "from skimage.metrics import structural_similarity as compare_ssim\n",
        "from skimage.restoration import denoise_bilateral\n",
        "from skimage.util import random_noise"
      ],
      "metadata": {
        "id": "83mISLv-ck3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DenoiseDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hr_dir,\n",
        "        hr_size=256,\n",
        "        sigmas=(0.01,0.03),\n",
        "        extensions=('png',)\n",
        "      ):\n",
        "\n",
        "        self.hr_paths = []\n",
        "        for ext in extensions:\n",
        "            self.hr_paths += glob(os.path.join(hr_dir, f'**/*.{ext}'), recursive=True)\n",
        "        self.hr_paths = sorted(self.hr_paths)\n",
        "        self.hr_size = hr_size\n",
        "        self.sigmas = sigmas\n",
        "        self.to_tensor = transforms.ToTensor()\n",
        "        self.resize_hr = transforms.Resize((hr_size, hr_size), interpolation=transforms.InterpolationMode.BICUBIC)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.hr_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.hr_paths[idx]\n",
        "        img = Image.open(path).convert('RGB')\n",
        "        img = self.resize_hr(img)\n",
        "\n",
        "        clean = np.asarray(img).astype(np.float32) / 255.0\n",
        "        sigma = random.choice(self.sigmas)\n",
        "\n",
        "        noisy_np = random_noise(clean, mode='gaussian', var=sigma ** 2)\n",
        "\n",
        "        clean = torch.from_numpy(clean.transpose(2, 0, 1)).float()\n",
        "        noisy = torch.from_numpy(noisy_np.transpose(2, 0, 1)).float()\n",
        "\n",
        "        return {'noisy': noisy, 'clean': clean, 'sigma': sigma, 'path': path}"
      ],
      "metadata": {
        "id": "5WeGmoQfctZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Down(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.conv = DoubleConv(in_ch, out_ch)\n",
        "    def forward(self,x):\n",
        "        return self.conv(self.pool(x))\n",
        "\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.conv = DoubleConv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        diffY = x2.size(2) - x1.size(2)\n",
        "        diffX = x2.size(3) - x1.size(3)\n",
        "        x1 = F.pad(x1, [diffX//2, diffX - diffX//2, diffY//2, diffY - diffY//2])\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class UNetDenoise(nn.Module):\n",
        "    def __init__(self, in_channels=3, base_filters=32):\n",
        "        super().__init__()\n",
        "        self.inc = DoubleConv(in_channels, base_filters)\n",
        "        self.down1 = Down(base_filters, base_filters*2)\n",
        "        self.down2 = Down(base_filters*2, base_filters*4)\n",
        "        self.bot = DoubleConv(base_filters*4, base_filters*8)\n",
        "        self.up2 = Up(base_filters*8 + base_filters*4, base_filters*4)\n",
        "        self.up1 = Up(base_filters*4 + base_filters*2, base_filters*2)\n",
        "        self.up0 = Up(base_filters*2 + base_filters, base_filters)\n",
        "        self.final = nn.Conv2d(base_filters, in_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        xb = self.bot(x3)\n",
        "        x = self.up2(xb, x3)\n",
        "        x = self.up1(x, x2)\n",
        "        x = self.up0(x, x1)\n",
        "        out = self.final(x)\n",
        "        out = torch.clamp(out, 0.0, 1.0)\n",
        "        return out"
      ],
      "metadata": {
        "id": "Sg8ex6AScuIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNetDenoiseV2(nn.Module):\n",
        "    def __init__(self, in_channels=3, base_filters=32):\n",
        "        super().__init__()\n",
        "        self.inc = DoubleConv(in_channels, base_filters)\n",
        "        self.down1 = Down(base_filters, base_filters*2)\n",
        "        self.down2 = Down(base_filters*2, base_filters*4)\n",
        "        self.down3 = Down(base_filters*4, base_filters*8)\n",
        "\n",
        "        self.bot = DoubleConv(base_filters*8, base_filters*16)\n",
        "\n",
        "        self.up3 = Up(base_filters*16 + base_filters*8, base_filters*8)\n",
        "        self.up2 = Up(base_filters*8 + base_filters*4, base_filters*4)\n",
        "        self.up1 = Up(base_filters*4 + base_filters*2, base_filters*2)\n",
        "        self.up0 = Up(base_filters*2 + base_filters, base_filters)\n",
        "\n",
        "        self.final = nn.Conv2d(base_filters, in_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x1 = self.inc(x)\n",
        "      x2 = self.down1(x1)\n",
        "      x3 = self.down2(x2)\n",
        "      x4 = self.down3(x3)\n",
        "\n",
        "      xb = self.bot(x4)\n",
        "\n",
        "      x_dec = self.up3(xb, x4)\n",
        "      x_dec = self.up2(x_dec, x3)\n",
        "      x_dec = self.up1(x_dec, x2)\n",
        "      x_dec = self.up0(x_dec, x1)\n",
        "\n",
        "      noise = self.final(x_dec)\n",
        "      out = x - noise\n",
        "      return torch.clamp(out, 0.0, 1.0)"
      ],
      "metadata": {
        "id": "sRRioyBg41E7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor_to_uint8_image(t):\n",
        "    arr = t.cpu().numpy()\n",
        "    arr = np.transpose(arr, (1,2,0))\n",
        "    arr = np.clip(arr*255.0, 0, 255).astype(np.uint8)\n",
        "    return arr\n",
        "\n",
        "def compute_psnr(hr_uint8, pred_uint8, data_range=255.0):\n",
        "    return compare_psnr(hr_uint8, pred_uint8, data_range=data_range)\n",
        "\n",
        "def compute_ssim_safe(hr_uint8, pred_uint8):\n",
        "    try:\n",
        "        return compare_ssim(hr_uint8, pred_uint8, data_range=255.0, channel_axis=2, win_size=7)\n",
        "    except TypeError:\n",
        "        return compare_ssim(hr_uint8, pred_uint8, data_range=255.0, multichannel=True, win_size=7)\n",
        "\n",
        "def compute_snr_db(hr_tensor, pred_tensor):\n",
        "    hr = hr_tensor.cpu().numpy()\n",
        "    pr = pred_tensor.cpu().numpy()\n",
        "    signal_power = np.sum(hr**2)\n",
        "    noise_power = np.sum((hr - pr)**2)\n",
        "    if noise_power <= 1e-12:\n",
        "        return float('inf')\n",
        "    return 10.0 * np.log10(signal_power / noise_power)\n",
        "\n",
        "def compute_lpips(lpips_fn, hr_tensor, pred_tensor):\n",
        "    hr_n = hr_tensor.unsqueeze(0) * 2.0 - 1.0\n",
        "    pr_n = pred_tensor.unsqueeze(0) * 2.0 - 1.0\n",
        "    with torch.no_grad():\n",
        "        d = lpips_fn(hr_n, pr_n, normalize=True)\n",
        "    return float(d.mean().cpu().numpy())"
      ],
      "metadata": {
        "id": "y_ljXxsJczQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_bilateral(\n",
        "    noisy_uint8,\n",
        "    sigma_color=0.05,\n",
        "    sigma_spatial=15\n",
        "  ):\n",
        "    img = noisy_uint8.astype(np.float32) / 255.0\n",
        "    den = denoise_bilateral(img, sigma_color=sigma_color, sigma_spatial=sigma_spatial, channel_axis=-1)\n",
        "    den_uint8 = np.clip(den * 255.0, 0, 255).astype(np.uint8)\n",
        "    return den_uint8"
      ],
      "metadata": {
        "id": "PHXRBMDic3CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(\n",
        "    model,\n",
        "    loader,\n",
        "    opt,\n",
        "    device,\n",
        "    criterion,\n",
        "    epoch,\n",
        "    lpips_fn=None\n",
        "  ):\n",
        "    model.train()\n",
        "    running = 0.0\n",
        "    pbar = tqdm(loader, desc=f\"Train {epoch}\")\n",
        "    for batch in pbar:\n",
        "        noisy = batch['noisy'].to(device)\n",
        "        clean = batch['clean'].to(device)\n",
        "        pred = model(noisy)\n",
        "        loss = criterion(pred, clean)\n",
        "        if lpips_fn is not None:\n",
        "            lp = lpips_fn((pred*2-1), (clean*2-1)).mean()\n",
        "            loss = loss + 0.1 * lp\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        running += loss.item()\n",
        "        pbar.set_postfix(loss = running / (pbar.n + 1))\n",
        "    return running / len(loader)\n",
        "\n",
        "def evaluate(\n",
        "    model,\n",
        "    loader,\n",
        "    device,\n",
        "    lpips_fn=None,\n",
        "  ):\n",
        "    model.eval()\n",
        "    results = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc=\"Eval\"):\n",
        "            noisy = batch['noisy'].to(device)\n",
        "            clean = batch['clean'].to(device)\n",
        "            paths = batch['path']\n",
        "\n",
        "            pred = model(noisy)\n",
        "\n",
        "            b = noisy.size(0)\n",
        "            for i in range(b):\n",
        "                clean_uint8 = tensor_to_uint8_image(clean[i])\n",
        "                noisy_uint8 = tensor_to_uint8_image(noisy[i])\n",
        "                pred_uint8 = tensor_to_uint8_image(pred[i])\n",
        "\n",
        "                psnr_pred = compute_psnr(clean_uint8, pred_uint8)\n",
        "                ssim_pred = compute_ssim_safe(clean_uint8, pred_uint8)\n",
        "                snr_pred = compute_snr_db(clean[i], pred[i])\n",
        "\n",
        "                lp_pred = None\n",
        "                if lpips_fn is not None:\n",
        "                    lp_pred = compute_lpips(lpips_fn, clean[i], pred[i])\n",
        "\n",
        "                results.append({\n",
        "                    'path': paths[i],\n",
        "                    'sigma': float(batch['sigma'][i]) if 'sigma' in batch else None,\n",
        "                    'psnr_pred': psnr_pred,\n",
        "                    'ssim_pred': ssim_pred,\n",
        "                    'snr_pred_db': snr_pred,\n",
        "                    'lpips_pred': lp_pred\n",
        "                })\n",
        "    return results"
      ],
      "metadata": {
        "id": "q4sECqxvc9w5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    noisy = torch.stack([item['noisy'] for item in batch], dim=0)\n",
        "    clean = torch.stack([item['clean'] for item in batch], dim=0)\n",
        "    sigs = torch.tensor([item['sigma'] for item in batch], dtype=torch.float32)\n",
        "    paths = [item['path'] for item in batch]\n",
        "    return {'noisy': noisy, 'clean': clean, 'sigma': sigs, 'path': paths}\n",
        "\n",
        "def save_results_csv(results, out_csv='results_denoise.csv'):\n",
        "    df = pd.DataFrame(results)\n",
        "    mean_row = {\n",
        "        'path': 'MEAN',\n",
        "        'sigma': df['sigma'].mean() if 'sigma' in df.columns else None,\n",
        "        'psnr_pred': df['psnr_pred'].mean(),\n",
        "        'ssim_pred': df['ssim_pred'].mean(),\n",
        "        'snr_pred_db': df['snr_pred_db'].replace([np.inf, -np.inf], np.nan).mean(),\n",
        "        'lpips_pred': df['lpips_pred'].mean() if 'lpips_pred' in df.columns else None,\n",
        "        'psnr_baseline': df['psnr_baseline'].mean() if 'psnr_baseline' in df.columns else None,\n",
        "        'ssim_baseline': df['ssim_baseline'].mean() if 'ssim_baseline' in df.columns else None,\n",
        "        'snr_baseline_db': df['snr_baseline_db'].replace([np.inf, -np.inf], np.nan).mean() if 'snr_baseline_db' in df.columns else None,\n",
        "        'lpips_baseline': df['lpips_baseline'].mean() if 'lpips_baseline' in df.columns else None,\n",
        "    }\n",
        "    df = pd.concat([df, pd.DataFrame([mean_row])], ignore_index=True)\n",
        "    df.to_csv(out_csv, index=False)\n",
        "    print(f\"Saved results to {out_csv}\")"
      ],
      "metadata": {
        "id": "bZ4qUUhBdAIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_args(args):\n",
        "    p = argparse.ArgumentParser()\n",
        "    p.add_argument('--train_dir', default='./train')\n",
        "    p.add_argument('--val_dir', default='./val')\n",
        "    p.add_argument('--hr_size', type=int, default=256)\n",
        "    p.add_argument('--epochs', type=int, default=30)\n",
        "    p.add_argument('--batch_size', type=int, default=8)\n",
        "    p.add_argument('--lr', type=float, default=1e-4)\n",
        "    p.add_argument('--base_filters', type=int, default=32)\n",
        "    p.add_argument('--num_workers', type=int, default=4)\n",
        "    p.add_argument('--resume', default='')\n",
        "    p.add_argument('--out_csv', default='results_denoise_v3.csv')\n",
        "    if args is None:\n",
        "        args, unknown = p.parse_known_args(sys.argv[1:])\n",
        "    else:\n",
        "        args, unknown = p.parse_known_args(args)\n",
        "\n",
        "    if unknown:\n",
        "        print(\"gnored unknown arguments:\", unknown)\n",
        "    return args"
      ],
      "metadata": {
        "id": "gHGlQj40dAxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(arg1):\n",
        "    args = parse_args(arg1)\n",
        "    device = torch.device('cuda' if (torch.cuda.is_available()) else 'cpu')\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    train_ds = DenoiseDataset(args.train_dir, hr_size=args.hr_size, sigmas=(0.01, 0.03))\n",
        "    val_ds = DenoiseDataset(args.val_dir, hr_size=args.hr_size, sigmas=(0.01, 0.03))\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=args.num_workers, collate_fn=collate_fn)\n",
        "\n",
        "    #model = UNetDenoise(in_channels=3, base_filters=args.base_filters).to(device)\n",
        "    model = UNetDenoiseV2(in_channels=3, base_filters=args.base_filters).to(device)\n",
        "\n",
        "\n",
        "    lpips_fn = lpips.LPIPS(net='alex').to(device)\n",
        "\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "    criterion = nn.L1Loss()\n",
        "\n",
        "    start_epoch = 1\n",
        "    if args.resume and os.path.exists(args.resume):\n",
        "        chk = torch.load(args.resume, map_location=device)\n",
        "        model.load_state_dict(chk['model'])\n",
        "        opt.load_state_dict(chk['opt'])\n",
        "        start_epoch = chk.get('epoch', 1) + 1\n",
        "        print(f\"Resumed from {args.resume}\")\n",
        "\n",
        "    best = None\n",
        "    for epoch in range(start_epoch, args.epochs + 1):\n",
        "        train_loss = train_one_epoch(model, train_loader, opt, device, criterion, epoch, lpips_fn=lpips_fn)\n",
        "        print(f\"Epoch {epoch} train loss: {train_loss:.6f}\")\n",
        "\n",
        "        torch.save({'model': model.state_dict(), 'opt': opt.state_dict(), 'epoch': epoch}, f'checkpoint_{epoch}.pth')\n",
        "\n",
        "        results = evaluate(model, val_loader, device, lpips_fn=lpips_fn)\n",
        "        out_csv = f\"{Path(args.out_csv).stem}_epoch{epoch}.csv\"\n",
        "        save_results_csv(results, out_csv=out_csv)\n",
        "\n",
        "        df = pd.DataFrame(results)\n",
        "        mean_psnr = df['psnr_pred'].mean()\n",
        "        if best is None or mean_psnr > best:\n",
        "            best = mean_psnr\n",
        "            torch.save({'model': model.state_dict(), 'opt': opt.state_dict(), 'epoch': epoch}, 'best_denoise.pth')\n",
        "            print(f\"New best model saved (epoch {epoch}) mean PSNR {mean_psnr:.4f}\")\n",
        "\n",
        "    print(\"Training finished. Best mean PSNR:\", best)"
      ],
      "metadata": {
        "id": "0x8Qeg3bdFme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main([\n",
        "    '--train_dir', '/content/DIV2K_train_HR',\n",
        "    '--val_dir', '/content/DIV2K_valid_HR',\n",
        "    '--epochs', '25',\n",
        "    '--batch_size', '4'\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9a_cAHgTdJ1r",
        "outputId": "becde3b6-cc8d-4cb8-8519-f298fd5e5537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from: /usr/local/lib/python3.12/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train 1: 100%|██████████| 200/200 [01:28<00:00,  2.27it/s, loss=0.0508]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 train loss: 0.050810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval: 100%|██████████| 100/100 [00:12<00:00,  7.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved results to results_denoise_v2_epoch1.csv\n",
            "New best model saved (epoch 1) mean PSNR 32.6396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain 2:   0%|          | 0/200 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train 2: 100%|██████████| 200/200 [01:27<00:00,  2.29it/s, loss=0.0246]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 train loss: 0.024551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval: 100%|██████████| 100/100 [00:12<00:00,  7.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved results to results_denoise_v2_epoch2.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain 3:   0%|          | 0/200 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train 3: 100%|██████████| 200/200 [01:26<00:00,  2.33it/s, loss=0.0236]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 train loss: 0.023637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval: 100%|██████████| 100/100 [00:12<00:00,  7.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved results to results_denoise_v2_epoch3.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain 4:   0%|          | 0/200 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train 4: 100%|██████████| 200/200 [01:27<00:00,  2.29it/s, loss=0.0221]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 train loss: 0.022120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval: 100%|██████████| 100/100 [00:12<00:00,  7.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved results to results_denoise_v2_epoch4.csv\n",
            "New best model saved (epoch 4) mean PSNR 34.2740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain 5:   0%|          | 0/200 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train 5: 100%|██████████| 200/200 [01:25<00:00,  2.34it/s, loss=0.0208]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 train loss: 0.020808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval: 100%|██████████| 100/100 [00:13<00:00,  7.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved results to results_denoise_v2_epoch5.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain 6:   0%|          | 0/200 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train 6: 100%|██████████| 200/200 [01:26<00:00,  2.32it/s, loss=0.0215]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 train loss: 0.021503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval: 100%|██████████| 100/100 [00:12<00:00,  7.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved results to results_denoise_v2_epoch6.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain 7:   0%|          | 0/200 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train 7: 100%|██████████| 200/200 [01:26<00:00,  2.31it/s, loss=0.0213]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 train loss: 0.021277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval: 100%|██████████| 100/100 [00:12<00:00,  7.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved results to results_denoise_v2_epoch7.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain 8:   0%|          | 0/200 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train 8: 100%|██████████| 200/200 [01:24<00:00,  2.36it/s, loss=0.0195]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 train loss: 0.019453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval: 100%|██████████| 100/100 [00:12<00:00,  7.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved results to results_denoise_v2_epoch8.csv\n",
            "New best model saved (epoch 8) mean PSNR 35.0697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain 9:   0%|          | 0/200 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train 9: 100%|██████████| 200/200 [01:26<00:00,  2.31it/s, loss=0.0188]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 train loss: 0.018818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval: 100%|██████████| 100/100 [00:12<00:00,  7.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved results to results_denoise_v2_epoch9.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain 10:   0%|          | 0/200 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train 10: 100%|██████████| 200/200 [01:26<00:00,  2.30it/s, loss=0.0185]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 train loss: 0.018531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval: 100%|██████████| 100/100 [00:12<00:00,  8.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved results to results_denoise_v2_epoch10.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain 11:   0%|          | 0/200 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Train 11:   8%|▊         | 16/200 [00:08<01:32,  1.99it/s, loss=0.0185]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2944511145.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m main([\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m'--train_dir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/DIV2K_train_HR'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m'--val_dir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/DIV2K_valid_HR'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m'--epochs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'25'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'--batch_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2923329554.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(arg1)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlpips_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlpips_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch} train loss: {train_loss:.6f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2230676399.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, opt, device, criterion, epoch, lpips_fn)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Train {epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mnoisy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'noisy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mclean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_baseline_denoising(noisy_uint8, sigma=None, method='bilateral'):\n",
        "    if method == 'bilateral':\n",
        "        sigma_color = float(sigma) if sigma is not None else 0.05\n",
        "        den_uint8 = baseline_bilateral(noisy_uint8, sigma_color=sigma_color, sigma_spatial=15)\n",
        "    elif method == 'none':\n",
        "        den_uint8 = noisy_uint8.copy()\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown baseline method: {method}\")\n",
        "\n",
        "    return {'method': method, 'denoised_uint8': den_uint8}"
      ],
      "metadata": {
        "id": "RTfzu9Dguvkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_solution(\n",
        "        model,\n",
        "        dataset,\n",
        "        device,\n",
        "        filename,\n",
        "        num_samples=8,\n",
        "        reference_implementation=None,\n",
        "    ):\n",
        "    model.eval()\n",
        "\n",
        "    n_total = len(dataset)\n",
        "    n = min(num_samples, n_total)\n",
        "\n",
        "    selected_indices = random.sample(range(n_total), n)\n",
        "    samples = [dataset[i] for i in selected_indices]\n",
        "\n",
        "    noisy = torch.stack([s['noisy'] for s in samples])\n",
        "    clean = torch.stack([s['clean'] for s in samples])\n",
        "    paths = [s['path'] for s in samples]\n",
        "    sigmas = [s['sigma'] for s in samples]\n",
        "\n",
        "    print(\"Images used for evaluation:\")\n",
        "    for p in paths:\n",
        "        print(\" -\", p)\n",
        "\n",
        "    lpips_model = lpips.LPIPS(net='alex').to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        noisy_device = noisy.to(device)\n",
        "        output = model(noisy_device)\n",
        "        if isinstance(output, (tuple, list)):\n",
        "            output = output[0]\n",
        "        output_cpu = output.cpu()\n",
        "\n",
        "        if reference_implementation is not None:\n",
        "            ref_outputs = []\n",
        "            for i in range(n):\n",
        "                sigma = float(sigmas[i])\n",
        "                path = paths[i]\n",
        "\n",
        "                noisy_uint8 = tensor_to_uint8_image(noisy[i])\n",
        "                clean_uint8 = tensor_to_uint8_image(clean[i])\n",
        "\n",
        "                baseline_result = run_baseline_denoising(noisy_uint8, sigma)\n",
        "                bas_uint8 = baseline_result['denoised_uint8']\n",
        "\n",
        "                ref_tensor = torch.from_numpy(bas_uint8.astype(np.float32) / 255.0).permute(2, 0, 1).to(device)\n",
        "                ref_outputs.append(ref_tensor)\n",
        "\n",
        "            ref_output_cpu = torch.stack(ref_outputs)\n",
        "        else:\n",
        "            ref_output_cpu = None\n",
        "\n",
        "    def compute_metrics(denoised, clean):\n",
        "        psnr_list, ssim_list, lpips_list = [], [], []\n",
        "        for i in range(n):\n",
        "            denoised_np = denoised[i].permute(1, 2, 0).numpy()\n",
        "            clean_np = clean[i].permute(1, 2, 0).numpy()\n",
        "            psnr_list.append(compare_psnr(clean_np, denoised_np, data_range=1.0))\n",
        "            ssim_val = compare_ssim(clean_np, denoised_np, data_range=1.0, channel_axis=2)\n",
        "            ssim_list.append(ssim_val)\n",
        "            lpips_val = lpips_model(\n",
        "                denoised[i].unsqueeze(0) * 2 - 1,\n",
        "                clean[i].unsqueeze(0) * 2 - 1\n",
        "            ).item()\n",
        "            lpips_list.append(lpips_val)\n",
        "        return {\n",
        "            \"PSNR\": np.mean(psnr_list),\n",
        "            \"SSIM\": np.mean(ssim_list),\n",
        "            \"LPIPS\": np.mean(lpips_list),\n",
        "        }\n",
        "\n",
        "    model_metrics = compute_metrics(output_cpu, clean)\n",
        "    if ref_output_cpu is not None:\n",
        "        ref_metrics = compute_metrics(ref_output_cpu, clean)\n",
        "    else:\n",
        "        ref_metrics = None\n",
        "\n",
        "    print(\"\\nMetrics (average over {} samples):\".format(n))\n",
        "    print(\"Main Model:\")\n",
        "    print(\" - PSNR: {:.2f}\".format(model_metrics[\"PSNR\"]))\n",
        "    print(\" - SSIM: {:.4f}\".format(model_metrics[\"SSIM\"]))\n",
        "    print(\" - LPIPS: {:.4f}\".format(model_metrics[\"LPIPS\"]))\n",
        "\n",
        "    if ref_metrics is not None:\n",
        "        print(\"\\nReference Implementation:\")\n",
        "        print(\" - PSNR: {:.2f}\".format(ref_metrics[\"PSNR\"]))\n",
        "        print(\" - SSIM: {:.4f}\".format(ref_metrics[\"SSIM\"]))\n",
        "        print(\" - LPIPS: {:.4f}\".format(ref_metrics[\"LPIPS\"]))\n",
        "\n",
        "    if ref_output_cpu is not None:\n",
        "        num_rows = 4\n",
        "        row_labels = ['Noisy', 'Denoised (Model)', 'Reference', 'Clean']\n",
        "        row_tensors = lambda col: [noisy, output_cpu, ref_output_cpu, clean]\n",
        "    else:\n",
        "        num_rows = 3\n",
        "        row_labels = ['Noisy', 'Denoised (Model)', 'Clean']\n",
        "        row_tensors = lambda col: [noisy, output_cpu, clean]\n",
        "\n",
        "    fig, axes = plt.subplots(num_rows, n, figsize=(max(4, n * 3), num_rows * 3))\n",
        "\n",
        "    if n == 1 and num_rows == 1:\n",
        "        axes = np.array([[axes]])\n",
        "    elif n == 1:\n",
        "        axes = np.expand_dims(axes, axis=1)\n",
        "    elif num_rows == 1:\n",
        "        axes = np.expand_dims(axes, axis=0)\n",
        "\n",
        "    for col in range(n):\n",
        "        imgs_for_col = row_tensors(col)\n",
        "        for row, img_tensor in enumerate(imgs_for_col):\n",
        "            img = img_tensor[col].permute(1, 2, 0).numpy()\n",
        "            img = np.clip(img, 0, 1)\n",
        "            axes[row, col].imshow(img)\n",
        "            axes[row, col].axis('off')\n",
        "        axes[0, col].set_title(f\"Sample {col + 1}\", fontsize=10)\n",
        "\n",
        "    left_margin = 0.08\n",
        "    plt.tight_layout(rect=[left_margin, 0, 1, 1])\n",
        "\n",
        "    for row, label in enumerate(row_labels):\n",
        "        y = 1.0 - (row + 0.5) / num_rows\n",
        "        fig.text(\n",
        "            left_margin / 2.0,\n",
        "            y,\n",
        "            label,\n",
        "            va='center',\n",
        "            ha='center',\n",
        "            fontsize=14,\n",
        "            fontweight='bold',\n",
        "            rotation='vertical',\n",
        "            rotation_mode='anchor'\n",
        "        )\n",
        "\n",
        "    plt.savefig(filename, bbox_inches='tight', dpi=200)\n",
        "    #plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "DeLaM0nmtknr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "checkpoint = torch.load(\"best_denoise.pth\", map_location=device)\n",
        "\n",
        "denoiser = UNetDenoiseV2()\n",
        "denoiser.to(device)\n",
        "denoiser.load_state_dict(checkpoint['model'])\n",
        "\n",
        "val_dataset = DenoiseDataset('./DIV2K_valid_HR', 256, (0.01, 0.03))\n",
        "\n",
        "evaluate_solution(\n",
        "    denoiser,\n",
        "    val_dataset,\n",
        "    device,\n",
        "    'denoised.png',\n",
        "    num_samples=8,\n",
        "    reference_implementation=baseline_bilateral\n",
        ")\n"
      ],
      "metadata": {
        "id": "rCdXl5_suZRs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "outputId": "3174f572-62d3-4186-964b-7eeeaaea2f0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3253317653.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"best_denoise.pth\", map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images used for evaluation:\n",
            " - ./DIV2K_valid_HR/0831.png\n",
            " - ./DIV2K_valid_HR/0898.png\n",
            " - ./DIV2K_valid_HR/0812.png\n",
            " - ./DIV2K_valid_HR/0861.png\n",
            " - ./DIV2K_valid_HR/0873.png\n",
            " - ./DIV2K_valid_HR/0895.png\n",
            " - ./DIV2K_valid_HR/0896.png\n",
            " - ./DIV2K_valid_HR/0857.png\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from: /usr/local/lib/python3.12/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/lpips/lpips.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.load_state_dict(torch.load(model_path, map_location='cpu'), strict=False)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3253317653.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDenoiseDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./DIV2K_valid_HR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.03\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m evaluate_solution(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdenoiser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3773620782.py\u001b[0m in \u001b[0;36mevaluate_solution\u001b[0;34m(model, dataset, device, filename, num_samples, reference_implementation)\u001b[0m\n\u001b[1;32m     71\u001b[0m         }\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mmodel_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mref_output_cpu\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mref_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_output_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3773620782.py\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(denoised, clean)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mssim_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare_ssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenoised_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mssim_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mssim_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             lpips_val = lpips_model(\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0mdenoised\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mclean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lpips/lpips.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, in0, in1, retPerLayer, normalize)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# v0.0 - original release had a bug, where input was not scaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0min0_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min1_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaling_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaling_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'0.1'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0min0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mouts0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min0_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min1_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mfeats0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiffs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lpips/lpips.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ]
    }
  ]
}